{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394e2eab",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6b2550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==2.7.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\saila\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip freeze | findstr torch\n",
    "\n",
    "#Check this and make sure you have torch 2.6 or greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "428741ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch>=2.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee9c73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saila\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692bc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load a 3-class sentiment model (supports positive, neutral, negative)\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"  # 3-class sentiment\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3192145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define label mapping\n",
    "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5716bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create test cases\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"I absolutely love this!\",\n",
    "        \"It's fine, nothing special.\",\n",
    "        \"This is terrible, I'm disappointed.\",\n",
    "        \"Best decision ever.\",\n",
    "        \"Not bad, could be better.\",\n",
    "        \"I hate it here.\",\n",
    "        \"Meh, it's okay.\",\n",
    "        \"Fantastic work! Keep it up.\",\n",
    "        \"I'm not sure how I feel.\",\n",
    "        \"Worst experience ever.\"\n",
    "    ],\n",
    "    \"label\": [2, 1, 0, 2, 1, 0, 1, 2, 1, 0]  # Ground truth labels\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "539c54db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Load pipeline and predict\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Hugging Face model returns logits-based labels like 'LABEL_0'\n",
    "preds = sentiment_pipeline(df[\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "019a4042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.9896766543388367},\n",
       " {'label': 'LABEL_2', 'score': 0.6005365252494812},\n",
       " {'label': 'LABEL_0', 'score': 0.9773134589195251},\n",
       " {'label': 'LABEL_2', 'score': 0.9259532690048218},\n",
       " {'label': 'LABEL_2', 'score': 0.6574769616127014},\n",
       " {'label': 'LABEL_0', 'score': 0.9738256335258484},\n",
       " {'label': 'LABEL_2', 'score': 0.6583998799324036},\n",
       " {'label': 'LABEL_2', 'score': 0.9814394116401672},\n",
       " {'label': 'LABEL_0', 'score': 0.6617536544799805},\n",
       " {'label': 'LABEL_0', 'score': 0.9699680805206299}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f228161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert predictions to numeric labels\n",
    "label_str_to_id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "pred_labels = [label_str_to_id[id2label[int(p['label'].split('_')[-1])]] for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6402f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Add predictions to the DataFrame\n",
    "df[\"predicted_label\"] = pred_labels\n",
    "df[\"predicted_sentiment\"] = df[\"predicted_label\"].map({0: \"negative\", 1: \"neutral\", 2: \"positive\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dc9ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         3\n",
      "     neutral       0.00      0.00      0.00         4\n",
      "    positive       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.42      0.67      0.51        10\n",
      "weighted avg       0.38      0.60      0.46        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saila\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\saila\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\saila\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Print the classification report\n",
    "print(\"ðŸ“‹ Classification Report:\\n\")\n",
    "print(classification_report(df[\"label\"], df[\"predicted_label\"], target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d189e42",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "- The model is biased towards the negative and positive classes, ignoring the neutral class completely.\n",
    "\n",
    "- The recall is perfect (1.00) for both negative and positive, but precision suffers, especially for the positive class.\n",
    "\n",
    "- The neutral class needs attention â€” consider:\n",
    "\n",
    "    Adding more training examples,\n",
    "\n",
    "    Adjusting class weights or loss function,\n",
    "\n",
    "    Reviewing data labeling consistency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
