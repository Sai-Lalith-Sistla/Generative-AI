{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Case Folding\n",
        "\n",
        "Case folding is a text normalization technique in Natural Language Processing (NLP) where all characters in a string are converted to the same case, typically lowercase. This ensures that words like \"Apple\", \"apple\", and \"APPLE\" are treated identically during processing, which is crucial for tasks like text classification, search, and matching. Case folding helps reduce vocabulary size and improves consistency, especially in languages where case doesn’t alter the meaning of words. However, it may not be suitable for languages or domains where case conveys semantic information (e.g., proper nouns or chemical symbols).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvFn_rH86azo",
        "outputId": "93c8f724-4a2c-4cbb-f2fa-52e135dcbf7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, And Welcome to My World\n"
          ]
        }
      ],
      "source": [
        "txt = \"Hello, And Welcome to My World\"\n",
        "print(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDpNQtAk8tdq",
        "outputId": "6cdca127-ec0a-4f1e-8878-9f35db6a7af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello, and welcome to my world\n"
          ]
        }
      ],
      "source": [
        "x = txt.casefold()\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Dd_Pi_8yMb",
        "outputId": "21901717-9800-41d7-cbf2-ba5497e6e2a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello, and welcome to my world\n"
          ]
        }
      ],
      "source": [
        "y = txt.lower()\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Special Character Removal\n",
        "\n",
        "Special character removal is a preprocessing step in NLP where non-alphanumeric characters such as punctuation marks, symbols, or emojis are stripped from the text. This is done to eliminate noise and focus on meaningful tokens that contribute to the analysis or modeling tasks. Commonly removed characters include `@`, `#`, `$`, `%`, and so on. While this step helps simplify the text and reduce dimensionality, care should be taken in domains where special characters have semantic significance—such as programming languages, social media handles, or sentiment expressions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MWbUWcN381ZU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello how are you\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "#input string\n",
        "input_str = \"hello how are$ you!!\"\n",
        "\n",
        "#Using regular expressions to remove special characters\n",
        "clean_str = re.sub(r\"[^a-zA-Z0-9\\s]\",\"\",input_str)\n",
        "\n",
        "print(clean_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello123 how are you\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "#input string\n",
        "input_str = \"hello123 how are$ you!!\"\n",
        "\n",
        "#Using regular expressions to remove special characters\n",
        "clean_str = re.sub(r\"[^a-zA-Z0-9\\s]\",\"\",input_str)\n",
        "\n",
        "print(clean_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries in the field of NLP\n",
        "\n",
        "- SpaCy - Natural language processing library in Python that can be used to tokenize and process textual data\n",
        "- nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Input string\n",
        "input_str = \"hello how are$ you!!\"\n",
        "\n",
        "# Function to clean the string\n",
        "def clean_text(text):\n",
        "  cleaned_text = ''.join(char for char in text if char.isalpha() or char.isspace())\n",
        "  doc = nlp(cleaned_text)\n",
        "  return ' '.join(token.text for token in doc)\n",
        "\n",
        "# Get the final output\n",
        "clean_str = clean_text(input_str)\n",
        "print(clean_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\saila\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello how are you\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "input_str = \"hello how are$ you!!\"\n",
        "\n",
        "# Tokenize\n",
        "tokens = nltk.word_tokenize(input_str)\n",
        "\n",
        "# Remove the special characters\n",
        "clean_tokens = [token for token in tokens if token.isalnum()]\n",
        "\n",
        "clean_str = ' '.join(clean_tokens)\n",
        "\n",
        "print(clean_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Contractions\n",
        "\n",
        "Contractions are shortened versions of words or combinations of words created by omitting certain letters and using an apostrophe, such as \"can't\" for \"cannot\" or \"they're\" for \"they are\". In NLP, expanding contractions is an important preprocessing step as it helps standardize the text and improve the performance of downstream tasks like sentiment analysis or machine translation. Without contraction handling, the model might treat \"isn't\" and \"is not\" as entirely different phrases, leading to inconsistencies. Contraction expansion is typically done using lookup dictionaries or regular expression-based methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.2.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "Downloading pyahocorasick-2.2.0-cp310-cp310-win_amd64.whl (34 kB)\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "\n",
            "   ---------- ----------------------------- 1/4 [anyascii]\n",
            "   ---------- ----------------------------- 1/4 [anyascii]\n",
            "   -------------------- ------------------- 2/4 [textsearch]\n",
            "   ---------------------------------------- 4/4 [contractions]\n",
            "\n",
            "Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\saila\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\saila\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\saila\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I cannot believe it is already raining\n"
          ]
        }
      ],
      "source": [
        "import contractions\n",
        "\n",
        "txt = \"I can't believe it's already raining\"\n",
        "\n",
        "expanded_txt = contractions.fix(txt)\n",
        "\n",
        "print(expanded_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Using regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def expand_contractions(text):\n",
        "  contractions_pattern = {\n",
        "      r\"(?i)can't\":\"cannot\",\n",
        "      r\"(?i)won't\":\"will not\",\n",
        "      r\"(?i)it's\":\"it is\",\n",
        "      r\"(?i)weren't\":\"were not\",\n",
        "      r\"(?i)I'm\":\"I am\",\n",
        "      r\"(?i)couldn't\":\"could not\"\n",
        "  }\n",
        "  for contraction, expansion in contractions_pattern.items():\n",
        "    text = re.sub(contraction,expansion,text)\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I could not visit my aunt's place yesterday\n"
          ]
        }
      ],
      "source": [
        "txt = \"I couldn't visit my aunt's place yesterday\"\n",
        "expanded_text = expand_contractions(txt)\n",
        "print(expanded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Tokenization\n",
        "\n",
        "Tokenization is the process of breaking down a sequence of text into smaller units called tokens, which can be words, subwords, or characters. It is a foundational step in NLP that enables machines to understand and manipulate text data. For instance, the sentence \"NLP is fun!\" can be tokenized into `[\"NLP\", \"is\", \"fun\", \"!\"]`. There are different types of tokenizers, such as whitespace tokenizers, regex-based tokenizers, and more sophisticated ones like WordPiece or Byte Pair Encoding (BPE) used in transformer models. The choice of tokenizer can significantly affect model performance and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\saila\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "# Sample text for tokenization\n",
        "txt = \"NLTK provides powerful tools for tokenization. It includes word tokenization and sentence tokenization\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NLTK', 'provides', 'powerful', 'tools', 'for', 'tokenization', '.', 'It', 'includes', 'word', 'tokenization', 'and', 'sentence', 'tokenization']\n"
          ]
        }
      ],
      "source": [
        "# Word tokenization\n",
        "words = word_tokenize(txt)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NLTK provides powerful tools for tokenization.', 'It includes word tokenization and sentence tokenization']\n"
          ]
        }
      ],
      "source": [
        "# Word tokenization\n",
        "sent = sent_tokenize(txt)\n",
        "print(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Stop Word Removal\n",
        "\n",
        "Stop word removal is a common text preprocessing technique in NLP where frequently occurring but semantically insignificant words—like \"the\", \"is\", \"and\", \"in\"—are filtered out. These words often do not contribute meaningful information for tasks like text classification or information retrieval and can be safely removed to reduce noise and dimensionality. Libraries such as NLTK and spaCy provide predefined lists of stop words that can be customized based on context. However, removing stop words isn't always beneficial, especially in tasks like sentiment analysis or translation, where even small words can carry important meaning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample Sentence\n",
        "sentence = \"This is a sample sentence, showing off the stop words filtration\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\saila\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\saila\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the Sentence\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "words = word_tokenize(sentence)\n",
        "\n",
        "# Filter out stopwords\n",
        "new_sentence = [word for word in words if word.lower() not in stopwords.words('english')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a sample sentence, showing off the stop words filtration\n",
            "['sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration']\n"
          ]
        }
      ],
      "source": [
        "# Print the final sentence\n",
        "print(sentence)\n",
        "print(new_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. N-grams\n",
        "\n",
        "N-grams are contiguous sequences of *n* items (typically words or characters) extracted from a text, used to capture local word order and context in NLP tasks. For example, for the sentence \"I love NLP\", the bigrams (2-grams) are \"I love\" and \"love NLP\". N-grams help preserve partial sentence structure and are useful in applications like text classification, language modeling, and machine translation. However, increasing the value of *n* can lead to high-dimensional and sparse representations, so a balance is often maintained between granularity and computational efficiency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\saila\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_ngrams(text, n):\n",
        "  tokens = word_tokenize(text)\n",
        "  n_grams = list(ngrams(tokens,n))\n",
        "  return n_grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('N-Grams',), ('are',), ('a',), ('sequence',), ('of',), ('n',), ('items',), ('from',), ('a',), ('given',), ('sample',), ('of',), ('text',), ('or',), ('speech',)]\n"
          ]
        }
      ],
      "source": [
        "# Example text\n",
        "txt = \"N-Grams are a sequence of n items from a given sample of text or speech\"\n",
        "\n",
        "unigrams = generate_ngrams(txt,1)\n",
        "print(unigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('N-Grams', 'are'), ('are', 'a'), ('a', 'sequence'), ('sequence', 'of'), ('of', 'n'), ('n', 'items'), ('items', 'from'), ('from', 'a'), ('a', 'given'), ('given', 'sample'), ('sample', 'of'), ('of', 'text'), ('text', 'or'), ('or', 'speech')]\n"
          ]
        }
      ],
      "source": [
        "bigrams = generate_ngrams(txt,2)\n",
        "print(bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('N-Grams', 'are', 'a'), ('are', 'a', 'sequence'), ('a', 'sequence', 'of'), ('sequence', 'of', 'n'), ('of', 'n', 'items'), ('n', 'items', 'from'), ('items', 'from', 'a'), ('from', 'a', 'given'), ('a', 'given', 'sample'), ('given', 'sample', 'of'), ('sample', 'of', 'text'), ('of', 'text', 'or'), ('text', 'or', 'speech')]\n"
          ]
        }
      ],
      "source": [
        "trigrams = generate_ngrams(txt,3)\n",
        "print(trigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Vectorization\n",
        "\n",
        "Vectorization is the process of converting text into numerical representations that machine learning models can understand. This transformation enables algorithms to process textual data by representing each word, sentence, or document as a vector of numbers. Common vectorization techniques include Count Vectorizer, TF-IDF, and more advanced methods like word embeddings. Proper vectorization is critical for model performance, as it determines how well the semantic and syntactic properties of text are captured.\n",
        "\n",
        "\n",
        "### 8. Word Embeddings\n",
        "\n",
        "Word embeddings are dense vector representations of words that capture their meaning and context based on usage in large corpora. Unlike sparse encodings like one-hot vectors, embeddings map words to continuous vector spaces where semantically similar words have closer vectors. Popular models for generating embeddings include Word2Vec, GloVe, and fastText. Embeddings significantly improve the performance of NLP models by preserving relationships such as similarity and analogy, enabling machines to understand deeper language structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Check out the code in Transformers folder\n",
        "\n",
        "files :\n",
        "- Word2Vec using genism\n",
        "- \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9. Bag of Words\n",
        "\n",
        "The Bag of Words (BoW) model is a simple yet effective technique for representing text data in NLP. It treats each document as a \"bag\" containing the words it includes, disregarding grammar and word order but maintaining frequency. Each document is converted into a vector based on word occurrences from a vocabulary. Though BoW is easy to implement and works well for basic tasks like document classification, it often results in sparse matrices and fails to capture word context or semantics, which can limit its performance on complex NLP problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('spam.csv')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Category\n",
              "ham     86.593683\n",
              "spam    13.406317\n",
              "Name: count, dtype: float64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Category.value_counts()/len(df)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category                                            Message  spam\n",
              "0      ham  Go until jurong point, crazy.. Available only ...     0\n",
              "1      ham                      Ok lar... Joking wif u oni...     0\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
              "3      ham  U dun say so early hor... U c already then say...     0\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...     0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['spam'] = df['Category'].apply(lambda x: 1 if x=='spam' else 0)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5572, 3)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4457,)\n",
            "(1115,)\n"
          ]
        }
      ],
      "source": [
        "#Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.Message, df.spam,test_size=0.2)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "(4457, 7735)\n"
          ]
        }
      ],
      "source": [
        "#Create bag of words representation using CountVectorizer\n",
        "v = CountVectorizer()\n",
        "\n",
        "X_train_cv = v.fit_transform(X_train.values)\n",
        "X_test_cv = v.transform(X_test)\n",
        "\n",
        "print(X_train_cv.toarray()[:2][0])\n",
        "print(X_train_cv.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'chgs'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v.get_feature_names_out()[1771]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ill': 3597,\n",
              " 'call': 1599,\n",
              " '2mrw': 406,\n",
              " 'at': 1116,\n",
              " 'ninish': 4779,\n",
              " 'with': 7543,\n",
              " 'my': 4654,\n",
              " 'address': 818,\n",
              " 'that': 6810,\n",
              " 'icky': 3573,\n",
              " 'american': 943,\n",
              " 'freek': 2979,\n",
              " 'wont': 7576,\n",
              " 'stop': 6495,\n",
              " 'callin': 1611,\n",
              " 'me': 4393,\n",
              " 'bad': 1193,\n",
              " 'jen': 3799,\n",
              " 'eh': 2547,\n",
              " 'just': 3862,\n",
              " 'do': 2372,\n",
              " 'what': 7469,\n",
              " 'ever': 2670,\n",
              " 'is': 3735,\n",
              " 'easier': 2508,\n",
              " 'for': 2931,\n",
              " 'you': 7699,\n",
              " 'sorry': 6336,\n",
              " 'cant': 1635,\n",
              " 'take': 6689,\n",
              " 'your': 7703,\n",
              " 'right': 5788,\n",
              " 'now': 4835,\n",
              " 'it': 3747,\n",
              " 'so': 6290,\n",
              " 'happens': 3319,\n",
              " 'there': 6833,\n",
              " '2waxsto': 421,\n",
              " 'wat': 7396,\n",
              " 'want': 7375,\n",
              " 'she': 6081,\n",
              " 'can': 1624,\n",
              " 'come': 1906,\n",
              " 'and': 965,\n",
              " 'get': 3105,\n",
              " 'her': 3402,\n",
              " 'medical': 4408,\n",
              " 'insurance': 3686,\n",
              " 'll': 4150,\n",
              " 'be': 1264,\n",
              " 'able': 761,\n",
              " 'to': 6936,\n",
              " 'deliver': 2233,\n",
              " 'have': 3347,\n",
              " 'basic': 1232,\n",
              " 'care': 1647,\n",
              " 'currently': 2114,\n",
              " 'shopping': 6117,\n",
              " 'the': 6814,\n",
              " 'give': 3134,\n",
              " 'til': 6899,\n",
              " 'friday': 2991,\n",
              " 'morning': 4572,\n",
              " 'thats': 6813,\n",
              " 'when': 7475,\n",
              " 'see': 5993,\n",
              " 'major': 4312,\n",
              " 'person': 5164,\n",
              " 'guide': 3262,\n",
              " 'went': 7456,\n",
              " 'ur': 7203,\n",
              " 'hon': 3465,\n",
              " 'lab': 3981,\n",
              " 'but': 1567,\n",
              " 'no': 4788,\n",
              " 'one': 4933,\n",
              " 'problem': 5435,\n",
              " 'we': 7413,\n",
              " 'will': 7513,\n",
              " 'spending': 6384,\n",
              " 'lot': 4203,\n",
              " 'of': 4885,\n",
              " 'quality': 5527,\n",
              " 'time': 6902,\n",
              " 'together': 6946,\n",
              " 'need': 4720,\n",
              " 'details': 2275,\n",
              " 'about': 763,\n",
              " 'online': 4937,\n",
              " 'job': 3820,\n",
              " 'hope': 3479,\n",
              " 'enjoyed': 2602,\n",
              " 'new': 4753,\n",
              " 'content': 1981,\n",
              " 'text': 6786,\n",
              " '61610': 578,\n",
              " 'unsubscribe': 7182,\n",
              " 'help': 3392,\n",
              " '08712400602450p': 101,\n",
              " 'provided': 5478,\n",
              " 'by': 1583,\n",
              " 'tones2you': 6968,\n",
              " 'co': 1867,\n",
              " 'uk': 7122,\n",
              " 'had': 3282,\n",
              " 'good': 3170,\n",
              " 'day': 2176,\n",
              " 'mine': 4472,\n",
              " 'was': 7389,\n",
              " 'really': 5617,\n",
              " 'busy': 1566,\n",
              " 'are': 1049,\n",
              " 'up': 7186,\n",
              " 'much': 4619,\n",
              " 'tomorrow': 6964,\n",
              " 'night': 4770,\n",
              " 'webpage': 7425,\n",
              " 'not': 4823,\n",
              " 'available': 1155,\n",
              " 'back': 1190,\n",
              " 'amp': 954,\n",
              " 're': 5598,\n",
              " 'packing': 5042,\n",
              " 'car': 1642,\n",
              " 'let': 4076,\n",
              " 'know': 3950,\n",
              " 'if': 3585,\n",
              " 'room': 5822,\n",
              " 'home': 3463,\n",
              " 'please': 5254,\n",
              " 'sweetheart': 6652,\n",
              " 'having': 3353,\n",
              " 'kind': 3930,\n",
              " 'loads': 4155,\n",
              " 'reasons': 5624,\n",
              " 'smile': 6260,\n",
              " 'biola': 1356,\n",
              " 'urgent': 7207,\n",
              " 'this': 6854,\n",
              " '2nd': 407,\n",
              " 'attempt': 1126,\n",
              " 'contact': 1978,\n",
              " 'won': 7570,\n",
              " '1000call': 261,\n",
              " '09071512432': 238,\n",
              " 'b4': 1178,\n",
              " '300603t': 432,\n",
              " 'csbcm4235wc1n3xx': 2086,\n",
              " 'callcost150ppmmobilesvary': 1604,\n",
              " 'max': 4381,\n",
              " '50': 538,\n",
              " 'yeah': 7672,\n",
              " 'bring': 1507,\n",
              " 'tape': 6708,\n",
              " 'measure': 4403,\n",
              " 'fri': 2990,\n",
              " 'haven': 3349,\n",
              " 'heard': 3369,\n",
              " 'anything': 1006,\n",
              " 'he': 3357,\n",
              " 'answering': 992,\n",
              " 'texts': 6797,\n",
              " 'guessing': 3260,\n",
              " 'flaked': 2882,\n",
              " 'said': 5886,\n",
              " 'jb': 3792,\n",
              " 'fantastic': 2781,\n",
              " 'change': 1717,\n",
              " 'again': 859,\n",
              " 'next': 4761,\n",
              " 'escalator': 2641,\n",
              " 'lookatme': 4185,\n",
              " 'thanks': 6804,\n",
              " 'purchase': 5504,\n",
              " 'video': 7284,\n",
              " 'clip': 1842,\n",
              " 'from': 3010,\n",
              " 've': 7261,\n",
              " 'been': 1287,\n",
              " 'charged': 1727,\n",
              " '35p': 451,\n",
              " 'think': 6846,\n",
              " 'better': 1327,\n",
              " 'why': 7498,\n",
              " 'send': 6017,\n",
              " 'in': 3625,\n",
              " 'mmsto': 4521,\n",
              " '32323': 446,\n",
              " 'wa': 7344,\n",
              " 'efficient': 2540,\n",
              " 'gee': 3085,\n",
              " 'thanx': 6808,\n",
              " 'course': 2036,\n",
              " '2yrs': 427,\n",
              " 'messages': 4442,\n",
              " 'on': 4929,\n",
              " 'messenger': 4444,\n",
              " 'lik': 4101,\n",
              " 'sending': 6019,\n",
              " 'cancelled': 1629,\n",
              " 'baby': 1186,\n",
              " 'well': 7450,\n",
              " 'sounds': 6347,\n",
              " 'important': 3615,\n",
              " 'understand': 7147,\n",
              " 'darlin': 2161,\n",
              " 'ring': 5792,\n",
              " 'later': 4018,\n",
              " 'fone': 2920,\n",
              " 'love': 4215,\n",
              " 'kate': 3890,\n",
              " 'its': 3755,\n",
              " 'poking': 5293,\n",
              " 'man': 4323,\n",
              " 'everyday': 2674,\n",
              " 'they': 6841,\n",
              " 'teach': 6732,\n",
              " 'canada': 1625,\n",
              " 'abi': 757,\n",
              " 'how': 3508,\n",
              " 'saying': 5933,\n",
              " 'hi': 3414,\n",
              " 'told': 6953,\n",
              " 'everything': 2679,\n",
              " 'dont': 2404,\n",
              " 'dehydrated': 2224,\n",
              " 'yes': 7684,\n",
              " 'fine': 2856,\n",
              " 'ok': 4911,\n",
              " 'umma': 7129,\n",
              " 'too': 6975,\n",
              " 'wonder': 7572,\n",
              " 'phone': 5191,\n",
              " 'battery': 1245,\n",
              " 'dead': 2184,\n",
              " 'tell': 6752,\n",
              " 'babe': 1183,\n",
              " 'all': 914,\n",
              " 'best': 1321,\n",
              " 'exam': 2697,\n",
              " 'could': 2025,\n",
              " 'seen': 6000,\n",
              " 'did': 2302,\n",
              " 'recognise': 5645,\n",
              " 'face': 2750,\n",
              " 'thk': 6855,\n",
              " 'some': 6302,\n",
              " 'em': 2570,\n",
              " 'find': 2853,\n",
              " 'wtc': 7627,\n",
              " 'far': 2783,\n",
              " 'weiyi': 7447,\n",
              " 'goin': 3158,\n",
              " 'rest': 5754,\n",
              " 'dunno': 2487,\n",
              " 'yet': 7687,\n",
              " 'dinner': 2331,\n",
              " 'den': 2241,\n",
              " 'might': 4456,\n",
              " 'join': 3827,\n",
              " 'weeks': 7440,\n",
              " 'savamob': 5926,\n",
              " 'member': 4426,\n",
              " 'offers': 4895,\n",
              " 'accessible': 779,\n",
              " '08709501522': 94,\n",
              " 'pobox': 5273,\n",
              " '139': 296,\n",
              " 'la3': 3979,\n",
              " '2wu': 424,\n",
              " 'only': 4939,\n",
              " 'week': 7435,\n",
              " 'mobile': 4527,\n",
              " 'great': 3220,\n",
              " 'offer': 4892,\n",
              " 'double': 2417,\n",
              " 'mins': 4481,\n",
              " 'txt': 7099,\n",
              " 'orange': 4973,\n",
              " 'tariffs': 6709,\n",
              " 'latest': 4019,\n",
              " 'camera': 1620,\n",
              " 'phones': 5193,\n",
              " 'free': 2974,\n",
              " 'mobileupd8': 4531,\n",
              " '08000839402': 52,\n",
              " 'or': 4969,\n",
              " '2stoptxt': 417,\n",
              " 'cs': 2085,\n",
              " 'remember': 5697,\n",
              " 'those': 6861,\n",
              " 'whom': 7493,\n",
              " 'hurt': 3545,\n",
              " 'during': 2491,\n",
              " 'days': 2177,\n",
              " 'satanic': 5917,\n",
              " 'imposter': 3619,\n",
              " 'pay': 5118,\n",
              " 'price': 5410,\n",
              " 'may': 4385,\n",
              " 'destiny': 2272,\n",
              " 'keep': 3898,\n",
              " 'going': 3159,\n",
              " 'as': 1086,\n",
              " 'pray': 5372,\n",
              " 'mind': 4470,\n",
              " 'over': 5021,\n",
              " 'same': 5900,\n",
              " 'wondar': 7571,\n",
              " 'full': 3029,\n",
              " 'flim': 2893,\n",
              " 'got': 3187,\n",
              " 'pple': 5355,\n",
              " 'type': 7112,\n",
              " 'message': 4440,\n",
              " 'lor': 4196,\n",
              " 'wan': 7371,\n",
              " 'hee': 3381,\n",
              " 'cos': 2013,\n",
              " 'noe': 4792,\n",
              " 'watch': 7397,\n",
              " 'infernal': 3653,\n",
              " 'affairs': 846,\n",
              " 'ask': 1096,\n",
              " 'along': 924,\n",
              " 'asking': 1100,\n",
              " 'shuhui': 6152,\n",
              " 'oso': 4993,\n",
              " 'finished': 2861,\n",
              " 'lunch': 4251,\n",
              " 'already': 926,\n",
              " 'wake': 7357,\n",
              " 'gran': 3205,\n",
              " 'onlyfound': 4940,\n",
              " 'out': 5003,\n",
              " 'afew': 844,\n",
              " 'ago': 870,\n",
              " 'cusoon': 2117,\n",
              " 'honi': 3472,\n",
              " 'aight': 880,\n",
              " 'fuck': 3019,\n",
              " 'im': 3600,\n",
              " 'late': 4015,\n",
              " 'tellmiss': 6754,\n",
              " 'way': 7409,\n",
              " 'taught': 6717,\n",
              " 'ranjith': 5580,\n",
              " 'sir': 6191,\n",
              " 'called': 1606,\n",
              " 'sms': 6272,\n",
              " 'like': 4102,\n",
              " 'becaus': 1273,\n",
              " 'hes': 3406,\n",
              " 'verifying': 7272,\n",
              " 'project': 5452,\n",
              " 'prabu': 5359,\n",
              " 'today': 6942,\n",
              " 'pa': 5039,\n",
              " 'mistake': 4504,\n",
              " 'thought': 6865,\n",
              " 'him': 3424,\n",
              " 'thing': 6844,\n",
              " 'get4an18th': 3106,\n",
              " 'loves': 4223,\n",
              " 'lov': 4213,\n",
              " 'line': 4114,\n",
              " 'truth': 7062,\n",
              " 'don': 2400,\n",
              " 'wil': 7509,\n",
              " 'tolerat': 6956,\n",
              " 'bcs': 1261,\n",
              " 'someone': 6306,\n",
              " 'never': 4749,\n",
              " 'comfort': 1910,\n",
              " 'lie': 4089,\n",
              " 'gud': 3252,\n",
              " 'ni8': 4763,\n",
              " 'sweet': 6650,\n",
              " 'dreams': 2443,\n",
              " 'alter': 930,\n",
              " '11': 273,\n",
              " 'pretty': 5404,\n",
              " 'pussy': 5513,\n",
              " 'any': 999,\n",
              " 'frm': 3002,\n",
              " 'wats': 7405,\n",
              " 'matter': 4377,\n",
              " 'reading': 5608,\n",
              " 'sent': 6024,\n",
              " 'meant': 4401,\n",
              " 'joke': 3830,\n",
              " 'read': 5605,\n",
              " 'light': 4099,\n",
              " 'also': 929,\n",
              " 'knows': 3953,\n",
              " 'menu': 4435,\n",
              " 'da': 2136,\n",
              " 'thangam': 6802,\n",
              " 'feel': 2807,\n",
              " 'very': 7274,\n",
              " 'happy': 3324,\n",
              " 'dear': 2188,\n",
              " 'miss': 4493,\n",
              " 'watching': 7400,\n",
              " 'tv': 7090,\n",
              " 'nice': 4765,\n",
              " 'then': 6827,\n",
              " 'smoking': 6270,\n",
              " 'while': 7486,\n",
              " 'people': 5146,\n",
              " 'use': 7220,\n",
              " 'wylie': 7637,\n",
              " 'smokes': 6268,\n",
              " 'justify': 3865,\n",
              " 'ruining': 5853,\n",
              " 'shit': 6102,\n",
              " 'nothing': 4827,\n",
              " 'tacos': 6682,\n",
              " 'rajas': 5564,\n",
              " 'burrito': 1561,\n",
              " 'jane': 3779,\n",
              " 'babes': 1184,\n",
              " 'wrk': 7618,\n",
              " 'after': 853,\n",
              " 'lst': 4237,\n",
              " 'nite': 4783,\n",
              " 'foned': 2921,\n",
              " 'cover': 2039,\n",
              " 'chuck': 1809,\n",
              " 'aiyo': 890,\n",
              " 'neva': 4747,\n",
              " 'reply': 5726,\n",
              " 'wait': 7353,\n",
              " 'lar': 4008,\n",
              " 'tot': 6996,\n",
              " 'havent': 3350,\n",
              " 'finish': 2859,\n",
              " 'bhaji': 1338,\n",
              " 'kallis': 3879,\n",
              " 'cricketer': 2070,\n",
              " 'sachin': 5874,\n",
              " 'world': 7591,\n",
              " 'tough': 7002,\n",
              " 'private': 5426,\n",
              " '2003': 344,\n",
              " 'account': 787,\n",
              " 'statement': 6459,\n",
              " 'shows': 6144,\n",
              " '800': 637,\n",
              " 'un': 7132,\n",
              " 'redeemed': 5658,\n",
              " 'points': 5291,\n",
              " '08715203694': 124,\n",
              " 'identifier': 3581,\n",
              " 'code': 1877,\n",
              " '40533': 482,\n",
              " 'expires': 2727,\n",
              " '31': 440,\n",
              " '10': 258,\n",
              " '04': 16,\n",
              " 'which': 7485,\n",
              " 'channel': 1721,\n",
              " 'where': 7479,\n",
              " 'boytoy': 1470,\n",
              " 'happened': 3316,\n",
              " 'gorgeous': 3183,\n",
              " 'pix': 5229,\n",
              " 'cumming': 2107,\n",
              " 'thank': 6803,\n",
              " 'found': 2957,\n",
              " 'dis': 2342,\n",
              " 'pierre': 5214,\n",
              " 'cardin': 1645,\n",
              " 'looks': 4189,\n",
              " 'normal': 4815,\n",
              " 'costs': 2018,\n",
              " '20': 341,\n",
              " 'sale': 5891,\n",
              " 'month': 4562,\n",
              " 'upto': 7201,\n",
              " 'more': 4568,\n",
              " 'calls': 1614,\n",
              " 'standard': 6441,\n",
              " 'network': 4744,\n",
              " 'charge': 1726,\n",
              " 'activate': 804,\n",
              " '9061100010': 727,\n",
              " 'wire3': 7532,\n",
              " 'net': 4738,\n",
              " '1st4terms': 334,\n",
              " 'pobox84': 5282,\n",
              " 'm26': 4270,\n",
              " '3uz': 474,\n",
              " 'cost': 2015,\n",
              " 'min': 4467,\n",
              " 'mobcudb': 4526,\n",
              " 'stretch': 6518,\n",
              " 'open': 4950,\n",
              " 'daddy': 2140,\n",
              " 'shu': 6150,\n",
              " 'looking': 4188,\n",
              " 'singapore': 6184,\n",
              " 'chachi': 1708,\n",
              " 'tried': 7046,\n",
              " 'calling': 1612,\n",
              " 'unable': 7133,\n",
              " 'reach': 5599,\n",
              " 'pl': 5232,\n",
              " 'missed': 4495,\n",
              " 'cal': 1593,\n",
              " 'once': 4932,\n",
              " 'tiz': 6921,\n",
              " 'msg': 4603,\n",
              " 'kanagu': 3882,\n",
              " 'look': 4184,\n",
              " 'lib': 4083,\n",
              " 'stuff': 6543,\n",
              " 'topic': 6985,\n",
              " 'rite': 5803,\n",
              " 'wewa': 7467,\n",
              " '130': 294,\n",
              " 'iriver': 3728,\n",
              " '255': 369,\n",
              " '128': 289,\n",
              " 'mb': 4388,\n",
              " 'awarded': 1169,\n",
              " 'city': 1816,\n",
              " 'break': 1487,\n",
              " 'win': 7516,\n",
              " '200': 342,\n",
              " 'summer': 6595,\n",
              " 'spree': 6414,\n",
              " 'every': 2671,\n",
              " 'wk': 7550,\n",
              " 'store': 6503,\n",
              " '88039': 703,\n",
              " 'skilgme': 6210,\n",
              " 'tscs087147403231winawk': 7069,\n",
              " 'age16': 863,\n",
              " '50perwksub': 545,\n",
              " 'jus': 3861,\n",
              " 'telling': 6753,\n",
              " 'dat': 2167,\n",
              " 'leaving': 4053,\n",
              " 'shanghai': 6072,\n",
              " '21st': 355,\n",
              " 'instead': 3683,\n",
              " 'haf': 3283,\n",
              " 'meet': 4411,\n",
              " 'cya': 2132,\n",
              " 'lets': 4077,\n",
              " '4get': 519,\n",
              " 'both': 1440,\n",
              " 'try': 7063,\n",
              " 'cheer': 1754,\n",
              " 'fit': 2874,\n",
              " 'soo': 6326,\n",
              " 'muchxxlove': 4620,\n",
              " 'locaxx': 4162,\n",
              " 'haha': 3284,\n",
              " 'used': 7221,\n",
              " 'driving': 2455,\n",
              " 'usf': 7225,\n",
              " 'stoners': 6493,\n",
              " 'nokia': 4798,\n",
              " '3510i': 450,\n",
              " 'colour': 1898,\n",
              " 'delivered': 2234,\n",
              " 'minutes': 4485,\n",
              " '100': 259,\n",
              " 'camcorder': 1618,\n",
              " '8000930705': 638,\n",
              " 'cool': 1998,\n",
              " 'wined': 7522,\n",
              " 'dined': 2327,\n",
              " 'before': 1293,\n",
              " 'hello': 3389,\n",
              " 'bath': 1240,\n",
              " 'hair': 3288,\n",
              " 'done': 2402,\n",
              " 'yellow': 7678,\n",
              " 'card': 1643,\n",
              " 'travel': 7032,\n",
              " 'has': 3334,\n",
              " 'gone': 3167,\n",
              " 'lt': 4238,\n",
              " 'gt': 3246,\n",
              " 'bucks': 1541,\n",
              " 'monthly': 4563,\n",
              " 'password': 5103,\n",
              " 'wap': 7380,\n",
              " 'mobsi': 4534,\n",
              " 'com': 1901,\n",
              " '391784': 458,\n",
              " 'pc': 5129,\n",
              " 'missing': 4497,\n",
              " 'sender': 6018,\n",
              " 'name': 4674,\n",
              " 'number': 4851,\n",
              " 'date': 2169,\n",
              " 'via': 7277,\n",
              " 'fullonsms': 3030,\n",
              " 'early': 2503,\n",
              " 'bird': 1357,\n",
              " 'purchases': 5505,\n",
              " 'horniest': 3489,\n",
              " 'dogging': 2386,\n",
              " 'service': 6035,\n",
              " 'sex': 6048,\n",
              " '2nite': 410,\n",
              " 'sign': 6165,\n",
              " 'follow': 2913,\n",
              " 'instructions': 3685,\n",
              " 'entry': 2618,\n",
              " '69888': 594,\n",
              " 'nyt': 4866,\n",
              " 'ec2a': 2520,\n",
              " '3lp': 465,\n",
              " '150p': 305,\n",
              " 'first': 2870,\n",
              " 'gonna': 3169,\n",
              " 'takes': 6692,\n",
              " 'part': 5085,\n",
              " 'wrc': 7611,\n",
              " 'rally': 5571,\n",
              " 'oz': 5038,\n",
              " 'lucozade': 4246,\n",
              " 'energy': 2594,\n",
              " 'le': 4041,\n",
              " '61200': 577,\n",
              " '25p': 370,\n",
              " 'packs': 5043,\n",
              " 'itcould': 3749,\n",
              " '1000': 260,\n",
              " 'txts': 7107,\n",
              " 'motorola': 4584,\n",
              " 'sonyericsson': 6325,\n",
              " 'bluetooth': 1401,\n",
              " 'call2optout': 1601,\n",
              " 'hf8': 3412,\n",
              " 'thanx4': 6809,\n",
              " 'cer': 1703,\n",
              " 'catch': 1677,\n",
              " 'ave': 1158,\n",
              " 'often': 4903,\n",
              " 'oh': 4906,\n",
              " 'soon': 6327,\n",
              " 'yourself': 7707,\n",
              " 'always': 936,\n",
              " 'slowly': 6248,\n",
              " 'becomes': 1277,\n",
              " 'habit': 3280,\n",
              " 'finally': 2850,\n",
              " 'life': 4091,\n",
              " 'blame': 1375,\n",
              " 'happiness': 3323,\n",
              " 'experience': 2723,\n",
              " 'essential': 2649,\n",
              " 'gods': 3155,\n",
              " 'blessings': 1386,\n",
              " 'low': 4227,\n",
              " 'scrounge': 5967,\n",
              " 'something': 6312,\n",
              " 'al': 894,\n",
              " 'does': 2380,\n",
              " 'moan': 4524,\n",
              " 'thin': 6843,\n",
              " 'goes': 3156,\n",
              " 'wrong': 7622,\n",
              " 'fault': 2794,\n",
              " 'de': 2183,\n",
              " 'arguments': 1059,\n",
              " 'fed': 2804,\n",
              " 'himso': 3426,\n",
              " 'bother': 1441,\n",
              " 'hav': 3343,\n",
              " '2go': 392,\n",
              " 'xx': 7649,\n",
              " 'being': 1303,\n",
              " 'talk': 6697,\n",
              " 'saturday': 5923,\n",
              " 'cherish': 1764,\n",
              " 'brother': 1523,\n",
              " 'role': 5817,\n",
              " 'model': 4539,\n",
              " 'go': 3150,\n",
              " 'movie': 4592,\n",
              " 'collect': 1891,\n",
              " 'oredi': 4981,\n",
              " 'polyphonic': 5303,\n",
              " 'ringtone': 5794,\n",
              " 'super': 6610,\n",
              " '87131': 697,\n",
              " 'poly': 5299,\n",
              " 'tone': 6965,\n",
              " '16': 315,\n",
              " 'sn': 6277,\n",
              " 'pobox202': 5277,\n",
              " 'nr31': 4840,\n",
              " '7zs': 635,\n",
              " 'subscription': 6565,\n",
              " '450pw': 503,\n",
              " 'mean': 4396,\n",
              " 'left': 4057,\n",
              " 'check': 1747,\n",
              " 'working': 7589,\n",
              " 'chikku': 1776,\n",
              " 'il': 3595,\n",
              " 'aftr': 857,\n",
              " '2000': 343,\n",
              " 'prize': 5428,\n",
              " 'guaranteed': 3250,\n",
              " '09061790126': 203,\n",
              " 'land': 3995,\n",
              " 'claim': 1819,\n",
              " '3030': 434,\n",
              " 'valid': 7244,\n",
              " '12hrs': 291,\n",
              " '150ppm': 309,\n",
              " 'wnt': 7561,\n",
              " 'buy': 1571,\n",
              " 'bmw': 1406,\n",
              " 'urgently': 7208,\n",
              " 'vry': 7330,\n",
              " 'hv': 3551,\n",
              " 'shortage': 6121,\n",
              " 'lacs': 3985,\n",
              " 'source': 6349,\n",
              " 'arng': 1067,\n",
              " 'amt': 958,\n",
              " 'prob': 5433,\n",
              " 'music': 4642,\n",
              " 'gift': 3120,\n",
              " 'vouchers': 7329,\n",
              " 'starting': 6452,\n",
              " 'word': 7583,\n",
              " 'draw': 2439,\n",
              " '87066': 693,\n",
              " 'tscs': 7068,\n",
              " 'www': 7636,\n",
              " 'ldew': 4038,\n",
              " 'skillgame': 6211,\n",
              " '1winaweek': 338,\n",
              " '150ppermesssubscription': 308,\n",
              " 'added': 814,\n",
              " 'their': 6820,\n",
              " 'list': 4130,\n",
              " 'place': 5233,\n",
              " 'visit': 7307,\n",
              " 'vl': 7314,\n",
              " 'adsense': 833,\n",
              " 'approved': 1036,\n",
              " 'girls': 3131,\n",
              " 'safe': 5881,\n",
              " 'selfish': 6009,\n",
              " 'arsenal': 1079,\n",
              " 'dartboard': 2165,\n",
              " 'condition': 1951,\n",
              " 'doubles': 2419,\n",
              " 'trebles': 7043,\n",
              " 'sure': 6625,\n",
              " 'yahoo': 7661,\n",
              " 'email': 2571,\n",
              " 'photos': 5196,\n",
              " 'yesterday': 7686,\n",
              " 'friends': 2996,\n",
              " 'us': 7216,\n",
              " 'problems': 5437,\n",
              " 'most': 4576,\n",
              " 'stupid': 6549,\n",
              " 'suggestion': 6585,\n",
              " 'lands': 4001,\n",
              " 'into': 3702,\n",
              " 'another': 986,\n",
              " 'helps': 3398,\n",
              " 'forgt': 2946,\n",
              " 'previous': 5407,\n",
              " 'alright': 927,\n",
              " 'bit': 1365,\n",
              " 'pls': 5262,\n",
              " 'ashley': 1091,\n",
              " 'hey': 3411,\n",
              " 'came': 1619,\n",
              " 'last': 4012,\n",
              " 'wun': 7635,\n",
              " 'signing': 6170,\n",
              " 'tmr': 6930,\n",
              " 'maybe': 4387,\n",
              " 'woke': 7565,\n",
              " 'fucking': 3022,\n",
              " 'wouldn': 7608,\n",
              " 'big': 1345,\n",
              " 'hockey': 3448,\n",
              " 'elections': 2561,\n",
              " 'shouldn': 6131,\n",
              " 'longer': 4182,\n",
              " 'than': 6800,\n",
              " 'an': 961,\n",
              " 'hour': 3501,\n",
              " 'though': 6864,\n",
              " 'designation': 2263,\n",
              " 'software': 6296,\n",
              " 'developer': 2282,\n",
              " 'chennai': 1762,\n",
              " 'shd': 6080,\n",
              " 'plus': 5267,\n",
              " 'minus': 4483,\n",
              " 'leave': 4051,\n",
              " 'between': 1330,\n",
              " 'paragraphs': 5073,\n",
              " '09095350301': 246,\n",
              " 'our': 5001,\n",
              " 'erotic': 2633,\n",
              " 'ecstacy': 2522,\n",
              " '60p': 576,\n",
              " '08712460324': 110,\n",
              " 'nat': 4690,\n",
              " 'rate': 5583,\n",
              " 'miles': 4461,\n",
              " 'smiles': 6262,\n",
              " 'made': 4292,\n",
              " 'letters': 4079,\n",
              " 'difference': 2313,\n",
              " 'keeps': 3900,\n",
              " 'even': 2664,\n",
              " 'am': 938,\n",
              " 'away': 1170,\n",
              " 'smiling': 6264,\n",
              " 'sleeping': 6227,\n",
              " 'bags': 1196,\n",
              " 'blanket': 1378,\n",
              " 'paper': 5067,\n",
              " 'else': 2567,\n",
              " 'swimming': 6657,\n",
              " 'pool': 5309,\n",
              " 'jacuzzi': 3771,\n",
              " 'house': 3503,\n",
              " 'nannys': 4684,\n",
              " 'awesome': 1171,\n",
              " 'omw': 4928,\n",
              " 'helloooo': 3391,\n",
              " 'welcomes': 7449,\n",
              " 'enjoy': 2601,\n",
              " 'joy': 3843,\n",
              " 'mrng': 4600,\n",
              " 'yo': 7694,\n",
              " 'netflix': 4740,\n",
              " 'wishing': 7539,\n",
              " 'family': 2773,\n",
              " 'merry': 4438,\n",
              " 'mas': 4358,\n",
              " 'year': 7673,\n",
              " 'advance': 836,\n",
              " 'shitload': 6106,\n",
              " 'welcome': 7448,\n",
              " 'giving': 3137,\n",
              " '08719839835': 155,\n",
              " 'future': 3043,\n",
              " 'mgs': 4448,\n",
              " 'billed': 1350,\n",
              " 'daily': 2143,\n",
              " 'cancel': 1627,\n",
              " '89123': 715,\n",
              " 'yup': 7720,\n",
              " 'timings': 6907,\n",
              " 'xuhui': 7648,\n",
              " 'learn': 4048,\n",
              " 'lesson': 4074,\n",
              " '8am': 719,\n",
              " 'picking': 5205,\n",
              " 'trash': 7029,\n",
              " 'hospital': 3493,\n",
              " 'doing': 2391,\n",
              " 'data': 2168,\n",
              " 'analysis': 963,\n",
              " 'starts': 6453,\n",
              " 'monday': 4553,\n",
              " 'thesis': 6837,\n",
              " 'entered': 2610,\n",
              " 'cabin': 1588,\n",
              " 'boss': 1437,\n",
              " 'felt': 2816,\n",
              " 'special': 6368,\n",
              " 'askd': 1097,\n",
              " 'invited': 3712,\n",
              " 'apartment': 1014,\n",
              " 'things': 6845,\n",
              " 'quick': 5536,\n",
              " 'question': 5533,\n",
              " 'must': 4645,\n",
              " 'taken': 6691,\n",
              " 'real': 5610,\n",
              " 'valentine': 7242,\n",
              " 'should': 6129,\n",
              " 'fb': 2799,\n",
              " 'jaykwon': 3789,\n",
              " 'thuglyfe': 6883,\n",
              " 'falconerf': 2767,\n",
              " 'arrange': 1072,\n",
              " 'santa': 5905,\n",
              " 'would': 7606,\n",
              " 'little': 4141,\n",
              " 'ones': 4934,\n",
              " 'xmas': 7646,\n",
              " 'eve': 2662,\n",
              " '09058094583': 177,\n",
              " 'book': 1422,\n",
              " 'carlos': 1659,\n",
              " 'definitely': 2219,\n",
              " 'coming': 1912,\n",
              " 'mu': 4617,\n",
              " 'tonight': 6970,\n",
              " 'excuses': 2706,\n",
              " 'package': 5041,\n",
              " 'programs': 5450,\n",
              " 'holiday': 3458,\n",
              " 'feeling': 2809,\n",
              " 'dentists': 2248,\n",
              " 'landline': 3997,\n",
              " 'asked': 1098,\n",
              " 'anna': 977,\n",
              " 'nagar': 4668,\n",
              " 'afternoon': 855,\n",
              " 'dun': 2485,\n",
              " 'believe': 1304,\n",
              " 'leh': 4063,\n",
              " 'true': 7057,\n",
              " 'muz': 4651,\n",
              " 'tog': 6945,\n",
              " 'brings': 1509,\n",
              " 'ringtones': 5796,\n",
              " 'chart': 1733,\n",
              " 'heroes': 3404,\n",
              " 'hit': 3432,\n",
              " 'each': 2499,\n",
              " 'pics': 5207,\n",
              " 'receiving': 5637,\n",
              " 'these': 6835,\n",
              " 'tips': 6910,\n",
              " 'until': 7184,\n",
              " '545': 558,\n",
              " 'ya': 7659,\n",
              " 'uniform': 7161,\n",
              " 'still': 6483,\n",
              " 'mmmmmmm': 4520,\n",
              " 'snuggles': 6289,\n",
              " 'deep': 2209,\n",
              " 'contented': 1982,\n",
              " 'sigh': 6162,\n",
              " 'whispers': 7488,\n",
              " 'barely': 1221,\n",
              " 'stand': 6440,\n",
              " 'minute': 4484,\n",
              " 'game': 3056,\n",
              " 'answers': 993,\n",
              " 'ques': 5532,\n",
              " 'suits': 6590,\n",
              " 'whats': 7471,\n",
              " 'staff': 6433,\n",
              " 'who': 7491,\n",
              " 'taking': 6694,\n",
              " 'class': 1825,\n",
              " 'office': 4896,\n",
              " 'module': 4541,\n",
              " 'humanities': 3534,\n",
              " 'sem': 6013,\n",
              " 'izzit': 3764,\n",
              " 'other': 4994,\n",
              " 'modules': 4542,\n",
              " '1st': 333,\n",
              " 'receipts': 5633,\n",
              " 'were': 7458,\n",
              " 'somewhere': 6316,\n",
              " 'fredericksburg': 2973,\n",
              " 'nah': 4669,\n",
              " 'wednesday': 7431,\n",
              " 'mini': 4474,\n",
              " 'cheetos': 1760,\n",
              " 'bag': 1195,\n",
              " 'hdd': 3356,\n",
              " 'casing': 1672,\n",
              " 'makes': 4314,\n",
              " 'dearer': 2190,\n",
              " 'them': 6823,\n",
              " 'pain': 5049,\n",
              " 'dem': 2239,\n",
              " 'didn': 2304,\n",
              " 'hear': 3368,\n",
              " 'laptop': 4007,\n",
              " 'someonone': 6307,\n",
              " 'trying': 7065,\n",
              " 'dating': 2172,\n",
              " '09064015307': 209,\n",
              " 'box334sk38ch': 1455,\n",
              " 'school': 5945,\n",
              " 'stay': 6463,\n",
              " 'weather': 7421,\n",
              " 'food': 2923,\n",
              " 'social': 6293,\n",
              " 'support': 6618,\n",
              " ...}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_np = X_train_cv.toarray()\n",
        "X_train_np[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 406,  818,  943, 1116, 1193, 1599, 1611, 2547, 2979, 3573, 3597,\n",
              "        3799, 4393, 4654, 4779, 6495, 6810, 7543, 7576], dtype=int64),)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(X_train_np[0]!=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Naive Bayes Classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_cv, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       973\n",
            "           1       0.98      0.92      0.95       142\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.98      0.96      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test_cv)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0], dtype=int64)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test on a random datapoint\n",
        "\n",
        "message = {\"Upto 20% off on parking, exclusing offer just for you\"}\n",
        "\n",
        "message_cnt = v.transform(message)\n",
        "\n",
        "model.predict(message_cnt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📦 Bag of Words: Pros and Cons\n",
        "\n",
        "| Pros                                                                                 | Cons                                                                                              |\n",
        "|--------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n",
        "| ✅ Simple and easy to implement — a great starting point for NLP problems.           | ❌ Ignores word order and syntax, losing sentence structure and context.                          |\n",
        "| ✅ Works well with traditional ML models like Naive Bayes, SVM, and Logistic Regression. | ❌ Cannot capture semantic similarity — treats synonyms as unrelated (e.g., \"happy\" vs \"joyful\"). |\n",
        "| ✅ Fast to compute and scale, especially for smaller datasets.                       | ❌ High dimensionality and sparsity for large vocabularies, leading to inefficient computations.  |\n",
        "| ✅ Produces interpretable features, enabling better understanding of model behavior. | ❌ Doesn't handle out-of-vocabulary words or unseen text gracefully.                             |\n",
        "| ✅ Performs well on simple classification tasks like spam detection or topic tagging.| ❌ No context awareness — phrases like \"not bad\" and \"bad\" may be misrepresented.                 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
