{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e1e1dbf",
   "metadata": {},
   "source": [
    "# Perplexity\n",
    "\n",
    "Perplexity (PPL) is a widely used intrinsic evaluation metric in language models that measures how well a model predicts a sample. It is the exponentiated average negative log-likelihood of the predicted tokens, where a lower perplexity indicates the model is more confident and accurate in its predictions. PPL helps assess the fluency and general quality of a language model's generation, with lower scores typically reflecting better language understanding and generation capabilities. However, it may not always correlate perfectly with downstream task performance or human judgment, especially for open-ended generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3350286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929ea565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d5d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [\n",
    "    \"Hyderabad is Capital of Telangana\",\n",
    "    \"Telangana Capital is Hyderabad the\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eefb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ppl(text):\n",
    "    encodings = tokenizer(text, return_tensors='pt')\n",
    "    input_ids = encodings['input_ids']\n",
    "\n",
    "    #compute loss\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels = input_ids)\n",
    "        loss = outputs.loss\n",
    "\n",
    "    ppl = torch.exp(loss).item()\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9b9a054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 : Hyderabad is Capital of Telangana\n",
      "PPL Score: 72.83\n",
      "\n",
      "Response 2 : Telangana Capital is Hyderabad the\n",
      "PPL Score: 400.18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate ppl for each output\n",
    "\n",
    "for i, response in enumerate(responses,1):\n",
    "    ppl = compute_ppl(response)\n",
    "    print(f\"Response {i} : {response}\")\n",
    "    print(f\"PPL Score: {ppl:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c3827",
   "metadata": {},
   "source": [
    "- Between the two responses, although both convey similar factual content, Response 1 (\"Hyderabad is Capital of Telangana\") has a significantly lower perplexity score (72.83) compared to Response 2 (\"Telangana Capital is Hyderabad the\") with a PPL of 400.18. \n",
    "- This indicates that Response 1 is more fluent and aligns better with typical language patterns learned by the model. \n",
    "- The higher perplexity for Response 2 reflects its unnatural word order and reduced grammaticality, highlighting how PPL can effectively capture sentence fluency and syntactic coherence even when semantic content remains similar.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
